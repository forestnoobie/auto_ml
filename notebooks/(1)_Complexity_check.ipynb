{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Complexity\n",
    "* Entropy\n",
    "* Validation Accuracy\n",
    "* model : Pretrained Resnet, Data : cifar-100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pretrained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from ptflops import get_model_complexity_info \n",
    "## Reference of ptflops: https://github.com/sovrasov/flops-counter.pytorch\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5848705988041283"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variable For training\n",
    "# You just use the following hyper-parameters\n",
    "BATCH_SIZE = 80\n",
    "NUM_EPOCH = 100\n",
    "LEARNING_RATE = 0.01\n",
    "CRITERION = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            # true_dist = pred.data.clone()\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model,train_loader, loss_idx):\n",
    "    model.train()\n",
    "    device = next(model.parameters()).device.index\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "    losses = []\n",
    "    for i, data in enumerate(train_loader):\n",
    "        image = data[0].type(torch.FloatTensor).cuda(device)\n",
    "        label = data[1].type(torch.LongTensor).cuda(device)\n",
    "\n",
    "        pred_label = model(image)\n",
    "        if loss_idx == 0 :\n",
    "            CRITERION = nn.CrossEntropyLoss()\n",
    "        elif loss_idx  == 1:\n",
    "\n",
    "            weights = [random.random() for i in range(100)]\n",
    "            weight = torch.FloatTensor(weights).cuda()\n",
    "            CRITERION = nn.CrossEntropyLoss(weight=weight)\n",
    "        elif loss_idx == 2 :\n",
    "            CRITERION = LabelSmoothingLoss(classes=10, smoothing=0.5)\n",
    "        elif loss_idx == 3 :\n",
    "            CRITERION = nn.MultiLabelMarginLoss()\n",
    "            \n",
    "            \n",
    "            \n",
    "        loss = CRITERION(pred_label, label)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    return avg_loss\n",
    "\n",
    "def eval(model, test_loader):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device.index\n",
    "    pred_labels = []\n",
    "    real_labels = []\n",
    "\n",
    "    for i, data in enumerate(test_loader):\n",
    "        image = data[0].type(torch.FloatTensor).cuda(device)\n",
    "        label = data[1].type(torch.LongTensor).cuda(device)\n",
    "        real_labels += list(label.cpu().detach().numpy())\n",
    "        \n",
    "        pred_label = model(image)\n",
    "        pred_label = list(pred_label.cpu().detach().numpy())\n",
    "        pred_labels += pred_label\n",
    "        \n",
    "    real_labels = np.array(real_labels)\n",
    "    pred_labels = np.array(pred_labels)\n",
    "    pred_labels = pred_labels.argmax(axis=1)\n",
    "    acc = sum(real_labels==pred_labels)/len(real_labels)*100\n",
    "    \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/nakyil/jupyter/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# CIFAR10 Dataset\n",
    "train_dataset = dsets.CIFAR100(root=data_path, train=True, \n",
    "                              transform=transforms.Compose([\n",
    "                                            transforms.RandomCrop(32, padding=4),\n",
    "                                            transforms.RandomHorizontalFlip(),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                                        ]), download=True)\n",
    "test_dataset = dsets.CIFAR100(root=data_path, train=False,\n",
    "                             transform=transforms.Compose([\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                                        ]))\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net18(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes):\n",
    "        super(Net18, self).__init__()\n",
    "        self.inp = 64\n",
    "        self.conv0 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, oup, num_block, stride=1):\n",
    "        layers = []\n",
    "        strides = [stride] + [1]*(num_block-1)\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inp, oup, stride))\n",
    "            self.inp = oup\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn0(self.conv0(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inp, oup, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        #####################################\n",
    "        \n",
    "        # Write down your own code\n",
    "        \n",
    "        self.is_prj_sc = stride != 1\n",
    "        \n",
    "        if self.is_prj_sc : self.conv1x1 = nn.Conv2d(in_channels=inp,out_channels=oup,stride=2,kernel_size=1)\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(in_channels=inp, out_channels=oup, kernel_size=3, stride=stride, padding=1, bias=False) \n",
    "        self.bn0 = nn.BatchNorm2d(oup)\n",
    "        self.relu0 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels=oup, out_channels=oup, kernel_size=3, stride=1, padding=1, bias=False) \n",
    "        self.bn1 = nn.BatchNorm2d(oup)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        #####################################\n",
    "        \n",
    "    def forward(self, x1):\n",
    "        \n",
    "        #####################################\n",
    "        \n",
    "        # Write down your own code\n",
    "        x = self.conv0(x1)\n",
    "        x = self.bn0(x)\n",
    "        x = self.relu0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        out = self.relu1(x)\n",
    "        if self.is_prj_sc :  \n",
    "            x = self.conv1x1(x1) # for project shortcut\n",
    "            out = out + x # residual connection\n",
    "        #####################################\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:26<44:19, 26.87s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:54<44:02, 26.96s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [01:21<43:50, 27.12s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [01:49<43:34, 27.23s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [02:16<43:21, 27.38s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [02:44<42:59, 27.44s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [03:12<42:41, 27.54s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [03:39<42:20, 27.61s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [04:07<41:55, 27.65s/it]\u001b[A\n",
      " 10%|█         | 10/100 [04:35<41:29, 27.66s/it]\u001b[A\n",
      " 11%|█         | 11/100 [05:03<41:04, 27.69s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [05:30<40:34, 27.67s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [05:58<40:05, 27.65s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [06:25<39:34, 27.61s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [06:53<39:00, 27.54s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [07:20<38:30, 27.50s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [07:48<38:04, 27.52s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [08:15<37:39, 27.56s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [08:43<37:17, 27.62s/it]\u001b[A\n",
      " 20%|██        | 20/100 [09:11<36:51, 27.64s/it]\u001b[A\n",
      " 21%|██        | 21/100 [09:38<36:24, 27.65s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [10:06<35:55, 27.64s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [10:34<35:27, 27.64s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [11:01<34:59, 27.63s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [11:29<34:32, 27.63s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [11:57<34:04, 27.63s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [12:24<33:34, 27.59s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [12:52<33:06, 27.59s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [13:19<32:38, 27.59s/it]\u001b[A\n",
      " 30%|███       | 30/100 [13:47<32:10, 27.58s/it]\u001b[A\n",
      " 31%|███       | 31/100 [14:14<31:44, 27.59s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [14:42<31:14, 27.57s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [15:09<30:42, 27.50s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [15:37<30:12, 27.46s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [16:04<29:44, 27.46s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [16:31<29:14, 27.42s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [16:59<28:47, 27.42s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [17:26<28:22, 27.45s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [17:54<27:56, 27.49s/it]\u001b[A\n",
      " 40%|████      | 40/100 [18:22<27:33, 27.55s/it]\u001b[A\n",
      " 41%|████      | 41/100 [18:49<27:09, 27.62s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [19:17<26:40, 27.59s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [19:44<26:11, 27.58s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [20:12<25:44, 27.59s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [20:40<25:17, 27.59s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [21:07<24:51, 27.61s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [21:35<24:23, 27.62s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [22:03<23:57, 27.64s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [22:30<23:26, 27.59s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [22:58<22:56, 27.53s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [23:25<22:27, 27.49s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [23:52<21:58, 27.46s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [24:20<21:28, 27.42s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [24:47<21:03, 27.47s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [25:15<20:39, 27.55s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [25:43<20:12, 27.57s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [26:10<19:45, 27.57s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [26:38<19:17, 27.56s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [27:05<18:51, 27.60s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [27:33<18:24, 27.61s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [28:01<17:56, 27.60s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [28:28<17:28, 27.61s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [28:56<17:01, 27.62s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [29:24<16:34, 27.63s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [29:51<16:05, 27.58s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [30:19<15:36, 27.55s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [30:46<15:08, 27.52s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [31:13<14:39, 27.49s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [31:41<14:11, 27.48s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [32:08<13:45, 27.51s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [32:36<13:19, 27.58s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [33:04<12:51, 27.57s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [33:31<12:24, 27.59s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [33:59<11:57, 27.60s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [34:27<11:30, 27.62s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [34:54<11:03, 27.66s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [35:22<10:36, 27.67s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [35:50<10:08, 27.66s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [36:17<09:40, 27.66s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [36:45<09:12, 27.64s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [37:12<08:44, 27.58s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [37:40<08:15, 27.54s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [38:07<07:47, 27.49s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [38:35<07:20, 27.53s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [39:03<06:54, 27.61s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [39:30<06:26, 27.61s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [39:58<05:59, 27.63s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [40:26<05:31, 27.62s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [40:53<05:03, 27.60s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [41:21<04:36, 27.61s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [41:48<04:08, 27.62s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [42:16<03:40, 27.60s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [42:44<03:13, 27.62s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [43:11<02:45, 27.62s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [43:39<02:18, 27.62s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [44:06<01:50, 27.58s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [44:34<01:22, 27.53s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [45:01<00:55, 27.52s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [45:29<00:27, 27.46s/it]\u001b[A\n",
      "100%|██████████| 100/100 [45:56<00:00, 27.56s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'list' object to buffer 'weight' (torch Tensor or None required)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-907b72b30603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtrain_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test_acc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'resnet'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-16e0525a1d45>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_loader, loss_idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mloss_idx\u001b[0m  \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mCRITERION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mloss_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mCRITERION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiLabelSoftMarginLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/auto_ml/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m    909\u001b[0m     def __init__(self, weight=None, size_average=None, ignore_index=-100,\n\u001b[1;32m    910\u001b[0m                  reduce=None, reduction='mean'):\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/auto_ml/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_WeightedLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/auto_ml/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mregister_buffer\u001b[0;34m(self, name, tensor)\u001b[0m\n\u001b[1;32m    137\u001b[0m             raise TypeError(\"cannot assign '{}' object to buffer '{}' \"\n\u001b[1;32m    138\u001b[0m                             \u001b[0;34m\"(torch Tensor or None required)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                             .format(torch.typename(tensor), name))\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot assign 'list' object to buffer 'weight' (torch Tensor or None required)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "train_list = []\n",
    "NUM_EPOCH = 100\n",
    "result_dict = {}\n",
    "\n",
    "\n",
    "CRITERION_dict = {}\n",
    "CRITERION_dict[0] = \"Cross Entropy\"\n",
    "CRITERION_dict[1] = \"Weighted Cross Entropy\"\n",
    "CRITERION_dict[2] = \"Smooth Label Cross Entropy\"\n",
    "CRITERION_dict[3] = 'MultiLabelMarginLoss'\n",
    "\n",
    "file_name = 'results.pkl'\n",
    "\n",
    "for idx in range(4):\n",
    "    ## Model initialization\n",
    "    resnet = Net18(ResidualBlock, [2, 2, 2, 2], 100).cuda()\n",
    "    train_list = []\n",
    "    \n",
    "    for i in tqdm(range(NUM_EPOCH)):\n",
    "        start_time = time.time()\n",
    "        loss = fit(resnet, train_loader, loss_idx=idx)\n",
    "        test_acc = eval(resnet, test_loader)\n",
    "        train_list.append({'epoch':i, 'loss':loss,'test_acc':test_acc, 'model':'resnet'})\n",
    "        end_time = time.time()\n",
    "        \n",
    "    result_dict[idx] = {'loss':CRITERION_dict[idx], 'train_log':train_list}\n",
    "    with open(file_name,'wb') as f:\n",
    "        pickle.dump(result_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name,'rb') as f:\n",
    "    r = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:27<44:34, 27.01s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:54<44:19, 27.14s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [01:21<44:00, 27.22s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [01:49<43:37, 27.27s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [02:16<43:20, 27.38s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [02:44<43:02, 27.47s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [03:12<42:39, 27.52s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [03:39<42:12, 27.53s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [04:07<41:45, 27.53s/it]\u001b[A\n",
      " 10%|█         | 10/100 [04:35<41:24, 27.61s/it]\u001b[A\n",
      " 11%|█         | 11/100 [05:02<41:00, 27.65s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [05:30<40:35, 27.67s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [05:58<40:11, 27.72s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [06:26<39:45, 27.74s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [06:54<39:21, 27.78s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [07:21<38:52, 27.77s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [07:49<38:23, 27.76s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [08:17<37:50, 27.69s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [08:44<37:19, 27.65s/it]\u001b[A\n",
      " 20%|██        | 20/100 [09:12<36:47, 27.59s/it]\u001b[A\n",
      " 21%|██        | 21/100 [09:39<36:16, 27.56s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [10:06<35:47, 27.53s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [10:34<35:16, 27.49s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [11:01<34:52, 27.53s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [11:29<34:27, 27.56s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [11:57<34:03, 27.62s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [12:25<33:37, 27.63s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [12:52<33:12, 27.68s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [13:20<32:45, 27.69s/it]\u001b[A\n",
      " 30%|███       | 30/100 [13:48<32:20, 27.72s/it]\u001b[A\n",
      " 31%|███       | 31/100 [14:16<31:54, 27.75s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [14:43<31:27, 27.76s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [15:11<30:56, 27.71s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [15:39<30:27, 27.68s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [16:06<29:56, 27.64s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [16:34<29:25, 27.59s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [17:01<28:59, 27.60s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [17:29<28:34, 27.66s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [17:57<28:09, 27.69s/it]\u001b[A\n",
      " 40%|████      | 40/100 [18:25<27:42, 27.71s/it]\u001b[A\n",
      " 41%|████      | 41/100 [18:52<27:15, 27.72s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [19:20<26:49, 27.74s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [19:48<26:20, 27.73s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [20:16<25:53, 27.74s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [20:43<25:25, 27.73s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [21:11<24:54, 27.67s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [21:38<24:24, 27.62s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [22:06<23:55, 27.61s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [22:33<23:26, 27.57s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [23:01<22:57, 27.56s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [23:29<22:32, 27.61s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [23:56<22:07, 27.66s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [24:24<21:40, 27.68s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [24:52<21:13, 27.68s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [25:20<20:46, 27.70s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [25:47<20:20, 27.73s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [26:15<19:53, 27.75s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [26:43<19:23, 27.69s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [27:10<18:55, 27.69s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [27:38<18:25, 27.64s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [28:05<17:56, 27.59s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [28:33<17:28, 27.58s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [29:01<17:00, 27.59s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [29:28<16:34, 27.64s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [29:56<16:09, 27.69s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [30:24<15:42, 27.71s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [30:52<15:15, 27.73s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [31:19<14:47, 27.74s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [31:47<14:20, 27.77s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [32:15<13:52, 27.77s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [32:43<13:26, 27.80s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [33:11<12:59, 27.83s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [33:39<12:30, 27.81s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [34:06<12:01, 27.74s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [34:34<11:31, 27.68s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [35:02<11:05, 27.71s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [35:29<10:37, 27.71s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [35:57<10:10, 27.75s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [36:25<09:42, 27.72s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [36:53<09:15, 27.77s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [37:20<08:47, 27.78s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [37:48<08:19, 27.73s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [38:16<07:50, 27.70s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [38:43<07:22, 27.66s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [39:11<06:54, 27.61s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [39:38<06:25, 27.56s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [40:06<05:57, 27.54s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [40:33<05:30, 27.53s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [41:01<05:02, 27.54s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [41:28<04:35, 27.52s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [41:56<04:07, 27.49s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [42:23<03:39, 27.48s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [42:51<03:13, 27.57s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [43:19<02:45, 27.63s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [43:46<02:18, 27.67s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [44:14<01:50, 27.69s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [44:42<01:23, 27.73s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [45:10<00:55, 27.72s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [45:37<00:27, 27.74s/it]\u001b[A\n",
      "100%|██████████| 100/100 [46:05<00:00, 27.66s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (80) must match the size of tensor b (100) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-66e0c47aaeef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test_acc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'resnet'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-aa09fee99e42>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_loader, loss_idx)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mCRITERION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiLabelMarginLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCRITERION\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/auto_ml/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/auto_ml/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultilabel_soft_margin_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/auto_ml/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmultilabel_soft_margin_loss\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2259\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2261\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlogsigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlogsigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (80) must match the size of tensor b (100) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for idx in range(1,4):\n",
    "    ## Model initialization\n",
    "    resnet = Net18(ResidualBlock, [2, 2, 2, 2], 100).cuda()\n",
    "    train_list = []\n",
    "    \n",
    "    for i in tqdm(range(NUM_EPOCH)):\n",
    "        start_time = time.time()\n",
    "        loss = fit(resnet, train_loader, loss_idx=idx)\n",
    "        test_acc = eval(resnet, test_loader)\n",
    "        train_list.append({'epoch':i, 'loss':loss,'test_acc':test_acc, 'model':'resnet'})\n",
    "        end_time = time.time()\n",
    "        \n",
    "    result_dict[idx] = {'loss':CRITERION_dict[idx], 'train_log':train_list}\n",
    "    with open(file_name,'wb') as f:\n",
    "        pickle.dump(result_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model,train_loader, loss_idx):\n",
    "    model.train()\n",
    "    device = next(model.parameters()).device.index\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "    losses = []\n",
    "    for i, data in enumerate(train_loader):\n",
    "        image = data[0].type(torch.FloatTensor).cuda(device)\n",
    "        label = data[1].type(torch.LongTensor).cuda(device)\n",
    "\n",
    "        pred_label = model(image)\n",
    "        if loss_idx == 0 :\n",
    "            CRITERION = nn.CrossEntropyLoss()\n",
    "        elif loss_idx  == 1:\n",
    "\n",
    "            weights = [random.random() for i in range(100)]\n",
    "            weight = torch.FloatTensor(weights).cuda()\n",
    "\n",
    "            CRITERION = nn.CrossEntropyLoss(weight=weight)\n",
    "        elif loss_idx == 2 :\n",
    "            CRITERION = nn.MultiLabelSoftMarginLoss()\n",
    "        elif loss_idx == 3 :\n",
    "            CRITERION = nn.MultiLabelMarginLoss()\n",
    "            \n",
    "        print(\"pred_label shape : {}, label : {}\".format(pred_label.size(),label.size()))\n",
    "            \n",
    "        loss = CRITERION(pred_label, label)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:26<44:10, 26.77s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:53<43:52, 26.86s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [01:21<43:40, 27.01s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [01:48<43:19, 27.07s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [02:15<43:01, 27.18s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [02:43<42:46, 27.31s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [03:11<42:27, 27.39s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [03:38<42:01, 27.41s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [04:05<41:34, 27.41s/it]\u001b[A\n",
      " 10%|█         | 10/100 [04:33<41:08, 27.43s/it]\u001b[A\n",
      " 11%|█         | 11/100 [05:00<40:40, 27.42s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [05:28<40:15, 27.45s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [05:55<39:54, 27.52s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [06:23<39:28, 27.54s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [06:51<39:02, 27.55s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [07:18<38:32, 27.53s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [07:46<38:01, 27.49s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [08:13<37:33, 27.48s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [08:40<37:05, 27.48s/it]\u001b[A\n",
      " 20%|██        | 20/100 [09:08<36:39, 27.49s/it]\u001b[A\n",
      " 21%|██        | 21/100 [09:36<36:15, 27.54s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [10:03<35:50, 27.58s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [10:31<35:26, 27.61s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [10:58<34:55, 27.58s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [11:26<34:24, 27.53s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [11:54<33:59, 27.55s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [12:21<33:35, 27.61s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [12:49<33:09, 27.63s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [13:16<32:36, 27.55s/it]\u001b[A\n",
      " 30%|███       | 30/100 [13:44<32:06, 27.52s/it]\u001b[A\n",
      " 31%|███       | 31/100 [14:11<31:39, 27.53s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [14:39<31:12, 27.54s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [15:06<30:42, 27.50s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [15:34<30:14, 27.49s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [16:01<29:45, 27.46s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [16:29<29:18, 27.48s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [16:56<28:53, 27.51s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [17:24<28:27, 27.55s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [17:52<28:02, 27.58s/it]\u001b[A\n",
      " 40%|████      | 40/100 [18:19<27:32, 27.54s/it]\u001b[A\n",
      " 41%|████      | 41/100 [18:46<27:02, 27.51s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [19:14<26:37, 27.54s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [19:42<26:10, 27.55s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [20:09<25:43, 27.55s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [20:37<25:18, 27.60s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [21:05<24:51, 27.62s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [21:32<24:20, 27.57s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [21:59<23:51, 27.52s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [22:27<23:22, 27.50s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [22:54<22:53, 27.47s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [23:22<22:25, 27.47s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [23:49<21:59, 27.48s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [24:17<21:33, 27.53s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [24:44<21:07, 27.56s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [25:12<20:38, 27.52s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [25:39<20:10, 27.52s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [26:07<19:42, 27.51s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [26:34<19:14, 27.49s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [27:02<18:46, 27.48s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [27:29<18:20, 27.50s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [27:57<17:54, 27.54s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [28:25<17:27, 27.55s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [28:52<17:00, 27.57s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [29:20<16:31, 27.55s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [29:47<16:03, 27.52s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [30:15<15:34, 27.49s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [30:42<15:07, 27.51s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [31:10<14:42, 27.57s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [31:37<14:15, 27.58s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [32:05<13:48, 27.60s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [32:33<13:19, 27.55s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [33:00<12:51, 27.56s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [33:28<12:26, 27.63s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [33:56<11:58, 27.64s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [34:23<11:31, 27.65s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [34:51<11:05, 27.72s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [35:19<10:37, 27.73s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [35:47<10:09, 27.72s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [36:14<09:42, 27.75s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [36:42<09:15, 27.76s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [37:10<08:47, 27.78s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [37:38<08:18, 27.70s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [38:05<07:49, 27.63s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [38:32<07:21, 27.57s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [39:00<06:52, 27.53s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [39:27<06:24, 27.50s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [39:55<05:57, 27.48s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [40:22<05:29, 27.46s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [40:50<05:02, 27.51s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [41:17<04:35, 27.57s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [41:45<04:08, 27.62s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [42:13<03:41, 27.63s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [42:41<03:13, 27.65s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [43:08<02:45, 27.65s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [43:36<02:18, 27.66s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [44:04<01:50, 27.68s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [44:31<01:23, 27.69s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [44:59<00:55, 27.66s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [45:27<00:27, 27.66s/it]\u001b[A\n",
      "100%|██████████| 100/100 [45:54<00:00, 27.55s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 3: inconsistent target size at /opt/conda/conda-bld/pytorch_1565272279342/work/aten/src/THCUNN/generic/MultiLabelMarginCriterion.cu:45",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-1aba89545ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test_acc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'resnet'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-82bd5b5d8194>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_loader, loss_idx)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCRITERION\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/auto_ml/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/auto_ml/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultilabel_margin_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/auto_ml/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmultilabel_margin_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2233\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2234\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2235\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultilabel_margin_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 3: inconsistent target size at /opt/conda/conda-bld/pytorch_1565272279342/work/aten/src/THCUNN/generic/MultiLabelMarginCriterion.cu:45"
     ]
    }
   ],
   "source": [
    "for idx in range(2,4):\n",
    "    ## Model initialization\n",
    "    resnet = Net18(ResidualBlock, [2, 2, 2, 2], 100).cuda()\n",
    "    train_list = []\n",
    "    \n",
    "    for i in tqdm(range(NUM_EPOCH)):\n",
    "        start_time = time.time()\n",
    "        loss = fit(resnet, train_loader, loss_idx=idx)\n",
    "        test_acc = eval(resnet, test_loader)\n",
    "        train_list.append({'epoch':i, 'loss':loss,'test_acc':test_acc, 'model':'resnet'})\n",
    "        end_time = time.time()\n",
    "        \n",
    "    result_dict[idx] = {'loss':CRITERION_dict[idx], 'train_log':train_list}\n",
    "    with open(file_name,'wb') as f:\n",
    "        pickle.dump(result_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict[2]['loss'] =  'SmoothCrossEntropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto_ml",
   "language": "python",
   "name": "auto_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
